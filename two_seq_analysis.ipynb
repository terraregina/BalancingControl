{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run first\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import chart_studio.plotly as py\n",
    "# import plotly.express as px\n",
    "import pandas as pd\n",
    "# import cufflinks as cf\n",
    "import json as js\n",
    "# cf.go_offline()\n",
    "# cf.set_config_file(offline=False, world_readable=True)\n",
    "import itertools\n",
    "# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "# init_notebook_mode(connected=False)\n",
    "# import plotly.io as pio\n",
    "# pio.renderers.default = 'notebook_connected'\n",
    "import os\n",
    "import action_selection as asl\n",
    "from itertools import product, repeat\n",
    "import jsonpickle as pickle\n",
    "import jsonpickle.ext.numpy as jsonpickle_numpy\n",
    "import json\n",
    "# import plotly.graph_objects as go\n",
    "import perception as prc\n",
    "import agent as agt\n",
    "from environment import PlanetWorld\n",
    "from agent import BayesianPlanner\n",
    "from world import World\n",
    "from planet_sequences import generate_trials_df\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "# functions\n",
    "def load_file_names(arrays, use_fitting=False):\n",
    "    lst = []\n",
    "    for i in product(*arrays):\n",
    "        lst.append(list(i))\n",
    "    \n",
    "    names = []\n",
    "    print('files to load: ' + str(len(lst)))\n",
    "    for li, l in enumerate(lst):\n",
    "\n",
    "        prefix = ''\n",
    "        if use_fitting == True:\n",
    "            prefix += 'fitt_'\n",
    "        else:\n",
    "            prefix +='hier_'\n",
    "\n",
    "        if l[0] == True:\n",
    "            prefix += 'switch1_'\n",
    "        else:\n",
    "            prefix +='switch0_'\n",
    "\n",
    "        if l[1] == True:\n",
    "            prefix += 'degr1_'\n",
    "        else:\n",
    "            prefix += 'degr0_'\n",
    "\n",
    "        fname = prefix + 'p' + str(l[4])  +'_learn_rew' + str(int(l[2] == True))+ '_q' + str(l[3]) + '_h' + str(l[5]) + '_' +\\\n",
    "        str(l[8]) + '_' + str(l[6]) + str(l[7])+ '_dec' + str(l[9])\n",
    "        # print(len(l))\n",
    "        if len(l) > 10:\n",
    "            fname += '_' + l[-1]\n",
    "        \n",
    "        fname +=  '_extinguish.json'\n",
    "\n",
    "        names.append(fname)\n",
    "\n",
    "\n",
    "    return names\n",
    "def load_df(names,data_folder='data', extinguish=None):\n",
    "    if extinguish is None:\n",
    "        raise('did not specify if rewarded during extinction')\n",
    "    # if not just_simulated:\n",
    "    path = os.path.join(os.getcwd(),data_folder)\n",
    "    #     names = os.listdir(path)\n",
    "    for fi, f in enumerate(names):\n",
    "        names[fi] = os.path.join(path,f)\n",
    "        # print(names[fi])\n",
    "\n",
    "    dfs = [None]*len(names)\n",
    "\n",
    "    for f,fname in enumerate(names):\n",
    "        jsonpickle_numpy.register_handlers()\n",
    "        with open(fname, 'r') as infile:\n",
    "            data = json.load(infile)\n",
    "        worlds = pickle.decode(data)\n",
    "        meta = worlds[-1]\n",
    "        agents = [w.agent for w in worlds[:-1]]\n",
    "        perception = [w.agent.perception for w in worlds[:-1]]\n",
    "        nt = worlds[0].T\n",
    "        npl = perception[0].npl\n",
    "        nr = worlds[0].agent.nr\n",
    "        nc = perception[0].nc\n",
    "        nw = len(worlds[:-1])\n",
    "        ntrials = meta['trials']\n",
    "        learn_rew = np.repeat(meta['learn_rew'], ntrials*nw*nt)\n",
    "        switch_cues = np.repeat(meta['switch_cues'], ntrials*nw*nt)\n",
    "        contingency_degradation = np.repeat(meta['contingency_degradation'], ntrials*nw*nt)\n",
    "        ntrials_df = np.repeat(meta['trials_per_block'], ntrials*nw*nt)\n",
    "        ndb = np.repeat(meta['degradation_blocks'], ntrials*nw*nt)\n",
    "        ntb = np.repeat(meta['training_blocks'], ntrials*nw*nt)\n",
    "        post_dir_rewards = [a.posterior_dirichlet_rew for a in agents]\n",
    "        post_dir_rewards = [post[:,1:,:,:] for post in post_dir_rewards]\n",
    "        entropy_rewards = np.zeros([nw*ntrials*nt,nc])\n",
    "        extinguished = np.zeros(ntrials*nw*nt, dtype='int32')\n",
    "        extinguished[:] = int(extinguish == True)\n",
    "        \n",
    "        for ip, post in enumerate(post_dir_rewards):\n",
    "            post = post.sum(axis=3)\n",
    "            norm = post.sum(axis=2)\n",
    "            reward_distributions = np.zeros(post.shape)\n",
    "\n",
    "            for r in range(nr):\n",
    "                reward_distributions[:,:,r,:] = np.divide(post[:,:,r,:],norm)\n",
    "            entropy = np.zeros([ntrials, nt, nc])\n",
    "\n",
    "            for trl in range(ntrials):\n",
    "                for t in range(nt-1):\n",
    "                    prob = reward_distributions[trl,t,:,:].T\n",
    "                    # if prob.sum() == 0:\n",
    "                    #     print('problem')\n",
    "                    entropy[trl,t+1,:] = -(np.log(prob)*prob).sum(axis=1)\n",
    "\n",
    "            entropy[:,0,:] = None\n",
    "            entropy_rewards[ip*(ntrials*nt):(ip+1)*(ntrials*nt),:] = np.reshape(entropy, [ntrials*nt,nc])\n",
    "\n",
    "        entropy_context = np.zeros(ntrials*nt*nw)\n",
    "        post_context = [a.posterior_context for a in agents]\n",
    "\n",
    "        for ip, post in enumerate(post_context):\n",
    "            entropy = np.zeros([ntrials, nt])\n",
    "\n",
    "            for trl in range(ntrials):\n",
    "                entropy[trl,:] = -(np.log(post[trl,:])*post[trl,:]).sum(axis=1) \n",
    "            entropy_context[ip*(ntrials*nt):(ip+1)*(ntrials*nt)] = np.reshape(entropy, [ntrials*nt])\n",
    "\n",
    "        posterior_context = [agent.posterior_context for agent in agents]\n",
    "        observations = [w.observations for w in worlds[:-1]]\n",
    "        context_cues = worlds[0].environment.context_cues\n",
    "        policies = worlds[0].agent.policies\n",
    "        actions = [w.actions[:,:3] for w in worlds[:-1]] \n",
    "        true_optimal = np.tile(np.repeat(meta['optimal_sequence'],nt), nw)\n",
    "        cue = np.tile(np.repeat(context_cues, nt), nw)\n",
    "        ex_p = np.zeros(ntrials)\n",
    "        executed_policy = np.zeros(nw*ntrials,dtype='int32')\n",
    "        optimality = np.zeros(nw*ntrials)\n",
    "        chose_optimal = np.zeros(nw*ntrials)\n",
    "\n",
    "        for w in range(nw):\n",
    "            for pi, p in enumerate(policies):\n",
    "                inds = np.where( (actions[w][:,0] == p[0]) & (actions[w][:,1] == p[1]) & (actions[w][:,2] == p[2]) )[0]\n",
    "                ex_p[inds] = pi\n",
    "            executed_policy[w*ntrials:(w+1)*ntrials] = ex_p\n",
    "            ch_op = executed_policy[w*ntrials:(w+1)*ntrials] == meta['optimal_sequence']\n",
    "            chose_optimal[w*ntrials:(w+1)*ntrials] = ch_op\n",
    "            optimality[w*ntrials:(w+1)*ntrials] = np.cumsum(ch_op)/(np.arange(ntrials)+1)\n",
    "\n",
    "        executed_policy = np.repeat(executed_policy, nt)\n",
    "        chose_optimal = np.repeat(chose_optimal, nt)\n",
    "        optimality = np.repeat(optimality, nt)\n",
    "        no = perception[0].generative_model_context.shape[0]\n",
    "        optimal_contexts = [np.argmax(perception[0].generative_model_contexts[i,:] for i in range(no))]\n",
    "        true_context = 0\n",
    "        q = np.repeat(meta['context_trans_prob'], ntrials*nw*nt)\n",
    "        p = np.repeat(meta['cue_ambiguity'], ntrials*nw*nt)\n",
    "        h = np.repeat(meta['h'], ntrials*nw*nt)\n",
    "        dec_temp = np.repeat(worlds[0].dec_temp,ntrials*nw*nt)\n",
    "        switch_cues = np.repeat(meta['switch_cues'], ntrials*nw*nt)\n",
    "        learn_rew = np.repeat(meta['learn_rew'], ntrials*nw*nt)\n",
    "        degradation = np.repeat('contingency_degradation', ntrials*nw*nt)\n",
    "        trial_type = np.tile(np.repeat(meta['trial_type'], nt), nw)\n",
    "        trial = np.tile(np.repeat(np.arange(ntrials),nt), nw)\n",
    "        run = np.repeat(np.arange(nw),nt*ntrials)\n",
    "        run.astype('str')\n",
    "        inferred_context_t0 = np.zeros(ntrials*nw,dtype='int32')\n",
    "        inferred_context_t3  = np.zeros(ntrials*nw,'int32')\n",
    "        agnt = np.repeat(np.arange(nw)+f*nw,nt*ntrials)\n",
    "        no, nc = perception[0].generative_model_context.shape \n",
    "        modes_gmc =  perception[0].generative_model_context.argsort(axis=1)\n",
    "        contexts = [modes_gmc[i,:][-2:] for i in range(no)] # arranged in ascending order!\n",
    "        if_inferred_context_switch = np.zeros(ntrials, dtype=\"int32\")\n",
    "\n",
    "        for i in range(no):    \n",
    "            c = np.array([contexts[i][-1]]*(meta['trials_per_block']*meta['training_blocks'])\\\n",
    "                + [contexts[i][-2]]*(meta['trials_per_block']*meta['degradation_blocks'])\\\n",
    "                + [contexts[i][-1]]*meta['trials_per_block']*2)\n",
    "            if_inferred_context_switch[np.where(context_cues == i)] = c[np.where(context_cues == i)]\n",
    "        inferred_switch = np.zeros(ntrials*nw,dtype='int32')\n",
    "        context_optimality = np.zeros(ntrials*nw)\n",
    "\n",
    "        for w in range(nw):\n",
    "            inferred_context_t0[w*ntrials:(w+1)*ntrials] = np.argmax(posterior_context[w][:,0,:],axis=1)\n",
    "            inferred_context_t3[w*ntrials:(w+1)*ntrials] = np.argmax(posterior_context[w][:,-1,:],axis=1)\n",
    "            inferred_switch[w*ntrials:(w+1)*ntrials] = if_inferred_context_switch == \\\n",
    "                                                    inferred_context_t3[w*ntrials:(w+1)*ntrials]\n",
    "            context_optimality[w*ntrials:(w+1)*ntrials] = np.cumsum(inferred_switch[w*ntrials:(w+1)*ntrials])\\\n",
    "                                                                /(np.arange(ntrials)+1)\n",
    "    \n",
    "        inferred_switch = np.repeat(inferred_switch, nt)\n",
    "        inferred_context_t0 = np.repeat(inferred_context_t0, nt)\n",
    "        inferred_context_t3 = np.repeat(inferred_context_t3, nt)\n",
    "        context_optimality = np.repeat(context_optimality, nt)\n",
    "        t = np.tile(np.arange(4), nw*ntrials)\n",
    "        \n",
    "        d = {'trial_type':trial_type, 'run':run, 'trial':trial, 't':t, 'true_optimal':true_optimal,\\\n",
    "                            'cue':cue, 'q':q, 'p':p, 'h':h, 'inferred_context_t0':inferred_context_t0,\\\n",
    "                            'inferred_context_t3':inferred_context_t3, 'executed_policy':executed_policy,\\\n",
    "                            'chose_optimal': chose_optimal, 'entropy_rew_c1': entropy_rewards[:,0], 'entropy_rew_c2': entropy_rewards[:,1], \\\n",
    "                            'entropy_rew_c3': entropy_rewards[:,2] , 'entropy_rew_c4': entropy_rewards[:,3],\\\n",
    "                            'policy_optimality':optimality,'agent':agnt, 'inferred_switch': inferred_switch,\\\n",
    "                            'context_optimality':context_optimality, 'learn_rew': learn_rew, 'entropy_context':entropy_context, \\\n",
    "                            'switch_cues':switch_cues, 'contingency_degradation': contingency_degradation,\\\n",
    "                            'degradation_blocks': ndb, 'training_blocks':ntb, 'trials_per_block': ntrials_df, \"dec_temp\":dec_temp} \n",
    "\n",
    "        # for key in d.keys():\n",
    "        #     print(key, np.unique(d[key].shape))\n",
    "        dfs[f] = pd.DataFrame(d)\n",
    "        \n",
    "    data = pd.concat(dfs)\n",
    "\n",
    "    groups = ['agent','run', 't','degradation_blocks', 'training_blocks', 'trials_per_block','learn_rew', 'p', 'q','h','cue']\n",
    "    grouped = data.groupby(by=groups)\n",
    "    data['iterator'] = 1\n",
    "    data['ith_cue_trial'] = grouped['iterator'].transform('cumsum')\n",
    "    data['policy_optimality_cue'] = grouped['chose_optimal'].transform('cumsum') / data['ith_cue_trial']\n",
    "    data['context_optimal_cue'] = grouped['inferred_switch'].transform('cumsum') / data['ith_cue_trial']\n",
    "    data.drop('iterator',1,inplace =True)\n",
    "    data.astype({'h': 'category'})\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def context_plot(query='p == 0.6'):\n",
    "\n",
    "    # context and policy optimality\n",
    "    fig = plt.figure(figsize=(10,3))\n",
    "    plt.subplot(1,2,1)\n",
    "    print('cue')\n",
    "    plot_df = base_df.query(query + '& t ==' + str(t) + ' & cue == ' + str(cue))\n",
    "    plot_df['h'] = plot_df['h'].astype('category')\n",
    "    ax = sns.lineplot(data=plot_df, x='trial', y='context_optimality', hue='h',\\\n",
    "                      palette=sns.color_palette('Blues_r',n_colors=np.unique(plot_df['h']).size), legend=False)\n",
    "    ax.set(ylim = (0,1.1))\n",
    "    ranges = plot_df.groupby('trial_type')['trial'].agg(['min', 'max'])\n",
    "    cols = [[1,1,1], [0,0,0],[1,1,1]] \n",
    "    for i, row in ranges.iterrows():\n",
    "        ax.axvspan(xmin=row['min'], xmax=row['max'], facecolor=cols[i], alpha=0.05)\n",
    "    # reward distribution entropy for different contexts\n",
    "    plt.subplot(1,2,2)\n",
    "    ax = sns.lineplot(data=plot_df, x='trial', y='policy_optimality', hue='h',\\\n",
    "            palette=sns.color_palette('Blues_r',n_colors=np.unique(plot_df['h']).size))\n",
    "    ax.legend(ncol = np.unique(plot_df['h']).size, bbox_to_anchor=(-2, -0.25), loc='upper left',\\\n",
    "              borderaxespad=0,title='h')\n",
    "    cols = [[1,1,1], [0,0,0],[1,1,1]] \n",
    "    for i, row in ranges.iterrows():\n",
    "        ax.axvspan(xmin=row['min'], xmax=row['max'], facecolor=cols[i], alpha=0.05)\n",
    "\n",
    "    ax.set(ylim = (0,1))\n",
    "    # title = base_query + ' & ' + query\n",
    "    # title = title.replace(' & ', ', ')\n",
    "    # title = title.replace('==', ':')\n",
    "    title = 'Inferred context and policy optimality for p: ' + query[-3:] + ', switch cues: '\\\n",
    "            + str(int(switch)) + ', degradation: ' + str(int(contingency_degr)) + \\\n",
    "            ', reward_naive: ' + str(int(reward_naive)) + ', cue_shown: ' + str(cue)\n",
    "    fig.suptitle(title, fontsize=15)\n",
    "\n",
    "\n",
    "\n",
    "def reward_entropy_plot(query='p == 0.6'):\n",
    "\n",
    "    # entropy of reward distribution for each context \n",
    "    plot_df = base_df.query(query + '& t ==' + str(t) + ' & cue == ' + str(cue))\n",
    "    plot_df['h'] = plot_df['h'].astype('category')\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(11, 7))\n",
    "    axs_flat = axs.flatten()\n",
    "    ranges = plot_df.groupby('trial_type')['trial'].agg(['min', 'max'])\n",
    "\n",
    "    legs = [False, False, False, True]\n",
    "    ys = ['entropy_rew_c1', 'entropy_rew_c2','entropy_rew_c3','entropy_rew_c4',]\n",
    "    for c in range(nc):\n",
    "        sns.lineplot(ax=axs_flat[c], data=plot_df, x='trial',y=ys[c],hue='h',\\\n",
    "            palette=sns.color_palette('Blues_r',n_colors=np.unique(plot_df['h']).size), legend=legs[c])\n",
    "        cols = [[1,1,1], [0,0,0],[1,1,1]]\n",
    "        for i, row in ranges.iterrows():\n",
    "            axs_flat[c].axvspan(xmin=row['min'], xmax=row['max'], facecolor=cols[i], alpha=0.05)\n",
    "        axs_flat[-1].legend(ncol = np.unique(plot_df['h']).size, bbox_to_anchor=(-2, -0.25), loc='upper left',\\\n",
    "                            borderaxespad=0.5,title='h')\n",
    "    \n",
    "    title = 'Reward distribution entropy for  p: ' + query[-3:] + ', switch cues: ' + str(int(switch)) +\\\n",
    "            ', degradation: ' + str(int(contingency_degr)) + ', reward_naive: ' + str(int(reward_naive)) + \\\n",
    "            ', cue_shown: ' + str(cue)\n",
    "    fig.suptitle(title, fontsize=15)\n",
    "\n",
    "def context_plot_cue_dependent(query='p == 0.6'):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,6), sharex = True)\n",
    "\n",
    "    lgnd = [False, True]\n",
    "    cues = [0,1]\n",
    "    titles_c = ['Inferred context optimality for cue 0','Inferred context optimality (at t4) for cue 1']\n",
    "    titles_p = ['Inferred policy optimality for cue 0','Inferred policy optimality for cue 1']\n",
    "\n",
    "    for cue in cues:\n",
    "        plot_df = base_df.query(query + '& t ==' + str(t) + ' & cue == ' + str(cue))\n",
    "\n",
    "        sns.lineplot(ax = axes[0,cue], data=plot_df, x='trial', y='context_optimal_cue', hue='h',\\\n",
    "                      palette=sns.color_palette('Blues_r',n_colors=np.unique(plot_df['h']).size),legend=False)\n",
    "        axes[0,cue].set_title(titles_c[cue])\n",
    "        axes[1,cue].set_title(titles_p[cue])\n",
    "        sns.lineplot(ax=axes[1,cue], data=plot_df, x='trial', y='policy_optimality_cue', hue='h',\\\n",
    "            palette=sns.color_palette('Blues_r',n_colors=np.unique(plot_df['h']).size), legend=lgnd[cue])\n",
    "    axes[1,1].legend(ncol = np.unique(plot_df['h']).size, bbox_to_anchor=(-2, -0.25), loc='upper left',\\\n",
    "              borderaxespad=0,title='h')\n",
    "    ranges = plot_df.groupby('trial_type')['trial'].agg(['min', 'max'])\n",
    "    cols = [[1,1,1], [0,0,0],[1,1,1]] \n",
    "    for ax in axes.flatten():\n",
    "        for i, row in ranges.iterrows():\n",
    "            ax.axvspan(xmin=row['min'], xmax=row['max'], facecolor=cols[i], alpha=0.05)\n",
    "    \n",
    "\n",
    "\n",
    "    # title = base_query + ' & ' + query\n",
    "    # title = title.replace(' & ', ', ')\n",
    "    # title = title.replace('==', ':')\n",
    "    title = 'p: ' + query[-3:] + ', switch cues: '\\\n",
    "            + str(int(switch)) + ', degradation: ' + str(int(contingency_degr)) + \\\n",
    "            ', reward_naive: ' + str(int(reward_naive))\n",
    "    fig.suptitle(title, fontsize=15)\n",
    "\n",
    "\n",
    "def load_df_animation_context(names,data_folder='temp'):\n",
    "\n",
    "    path = os.path.join(os.getcwd(),data_folder)\n",
    "    #     names = os.listdir(path)\n",
    "\n",
    "    for fi, f in enumerate(names):\n",
    "        names[fi] = os.path.join(path,f)\n",
    "\n",
    "    print(names)\n",
    "    overall_df = [None for _ in range(len(names))]\n",
    "    for f,fname in enumerate(names):\n",
    "        jsonpickle_numpy.register_handlers()\n",
    "\n",
    "        with open(fname, 'r') as infile:\n",
    "            data = json.load(infile)\n",
    "\n",
    "        worlds = pickle.decode(data)\n",
    "        meta = worlds[-1]\n",
    "        nw = len(worlds[:-1])\n",
    "        agents = [w.agent for w in worlds[:-1]]\n",
    "        posterior_context = [agent.posterior_context for agent in agents]\n",
    "        ntrials, t, nc = posterior_context[0].shape\n",
    "        outcome_surprise = [agent.outcome_suprise for agent in agents]\n",
    "        policy_surprise = [agent.policy_surprise for agent in agents]\n",
    "        policy_entropy = [agent.policy_entropy for agent in agents]\n",
    "        npi = agents[0].posterior_policies.shape[2]\n",
    "        taus = np.arange(ntrials)\n",
    "        ts = np.arange(t)\n",
    "        cs = np.arange(nc)\n",
    "        pis_post = np.array(['post_' for _ in range(npi)], dtype=object) + np.array([str(i) for i in range(npi)], dtype=object)\n",
    "        pis_prior = np.array(['post_' for _ in range(npi)], dtype=object) + np.array([str(i) for i in range(npi)], dtype=object)\n",
    "        pis_like = np.array(['post_' for _ in range(npi)], dtype=object) + np.array([str(i) for i in range(npi)], dtype=object)\n",
    "\n",
    "        mi = pd.MultiIndex.from_product([taus, ts, cs], names=['trial', 't', 'context'])\n",
    "        mi_post = pd.MultiIndex.from_product([taus, ts, pis_post, cs], names=['trial', 't', 'policy','context'])\n",
    "        mi_like = pd.MultiIndex.from_product([taus, ts, pis_like, cs], names=['trial', 't', 'policy','context'])\n",
    "        mi_prior = pd.MultiIndex.from_product([taus, ts, pis_like, cs], names=['trial', 't', 'policy','context'])\n",
    "\n",
    "        dfs = [None for _ in range(nw)]\n",
    "        factor = ntrials*nc*t\n",
    "\n",
    "        for w in range(nw):\n",
    "\n",
    "            policy_post_df =  pd.Series(index=mi_post, data=agents[w].posterior_policies.flatten())\n",
    "            policy_post_df = policy_post_df.unstack(level='policy').reset_index()\n",
    "            # fix entropy calcs\n",
    "            policy_prob = policy_post_df.iloc[:,-8:].to_numpy()\n",
    "            policy_prob[policy_prob == 0] = 10**(-300)\n",
    "            entropy = -(policy_prob*np.log(policy_prob)).sum(axis=1)\n",
    "\n",
    "            prior_policies = np.tile(agents[w].prior_policies[:,np.newaxis,:,:], (1,t,1,1))\n",
    "            # print(np.all(prior_policies[:,0,:,:] == prior_policies[:,1,:,:] ))\n",
    "            policy_prior_df =  pd.Series(index=mi_prior, data=prior_policies.flatten())\n",
    "            policy_prior_df = policy_prior_df.unstack(level='policy').reset_index()\n",
    "\n",
    "            policy_like_df =  pd.Series(index=mi_like, data=agents[w].likelihood.flatten())\n",
    "            policy_like_df = policy_like_df.unstack(level='policy').reset_index()\n",
    "            \n",
    "            policy_entropy_df = pd.Series(index=mi,\\\n",
    "                data=policy_entropy[w].flatten()).reset_index().rename(columns = {0:'policy_entropy'})\n",
    "            \n",
    "            policy_surprise_df = pd.Series(index=mi,\\\n",
    "                data=policy_surprise[w].flatten()).reset_index().rename(columns = {0:'context_obs_surprise'})\n",
    "            outcome_surprise_df = pd.Series(index=mi,\\\n",
    "                data=outcome_surprise[w].flatten()).reset_index().rename(columns = {0:'outcome_surprise'})\n",
    "                \n",
    "            # break\n",
    "            df = pd.Series(index=mi, data=posterior_context[w].flatten())\n",
    "            df = df.reset_index().rename(columns = {0:'probability'})\n",
    "            df['context_obs_surprise'] = policy_surprise_df['context_obs_surprise']\n",
    "            df['outcome_surprise'] = outcome_surprise_df['outcome_surprise']\n",
    "            df['policy_entropy'] = policy_entropy_df['policy_entropy']\n",
    "            # df['policy_entropy'] = policy_entropy_df['policy_entropy']\n",
    "            df['learn_rew'] = np.repeat(meta['learn_rew'], factor)\n",
    "            df['switch_cues'] = np.repeat(meta['switch_cues'], factor)\n",
    "            df['contingency_degradation'] = np.repeat(meta['contingency_degradation'], factor)\n",
    "            df['trials_per_block'] = np.repeat(meta['trials_per_block'], factor)\n",
    "            df['degradation_blocks'] = np.repeat(meta['degradation_blocks'], factor)\n",
    "            df['training_blocks'] = np.repeat(meta['training_blocks'], factor)\n",
    "            df['context_cues'] = np.repeat(worlds[0].environment.context_cues, nc*t)\n",
    "            df['true_optimal'] = np.repeat(meta['optimal_sequence'], nc*t)\n",
    "            df['q'] = np.repeat(meta['context_trans_prob'], factor)\n",
    "            df['p'] = np.repeat(meta['cue_ambiguity'], factor)\n",
    "            df['h'] = np.repeat(meta['h'], factor)\n",
    "            df['run'] = np.repeat(w,factor)\n",
    "            df['trial_type'] = np.repeat(meta['trial_type'], nc*t)\n",
    "            df['trial'] = np.repeat(np.arange(ntrials), nc*t)\n",
    "            df['agent'] = np.repeat(w+f*nw,factor)\n",
    "            df = df.join(policy_post_df.iloc[:,-8:])\n",
    "            dfs[w] = df\n",
    "            break\n",
    "        overall_df[f] = pd.concat(dfs)\n",
    "    data_animation = pd.concat(overall_df)\n",
    "    # data_animation.to_excel('data_animation.xlsx')\n",
    "    return data_animation\n",
    "# data_animation.to_csv('data_animation.csv')\n",
    "\n",
    "\n",
    "def load_df_animation_pol(names,data_folder='temp'):\n",
    "\n",
    "    path = os.path.join(os.getcwd(),data_folder)\n",
    "    #     names = os.listdir(path)\n",
    "\n",
    "    for fi, f in enumerate(names):\n",
    "        names[fi] = os.path.join(path,f)\n",
    "\n",
    "\n",
    "    overall_df = [None for _ in range(len(names))]\n",
    "    for f,fname in enumerate(names):\n",
    "        jsonpickle_numpy.register_handlers()\n",
    "\n",
    "        with open(fname, 'r') as infile:\n",
    "            data = json.load(infile)\n",
    "\n",
    "        worlds = pickle.decode(data)\n",
    "        meta = worlds[-1]\n",
    "        nw = len(worlds[:-1])\n",
    "        agents = [w.agent for w in worlds[:-1]]\n",
    "        posterior_context = [agent.posterior_context for agent in agents]\n",
    "        ntrials, t, nc = posterior_context[0].shape\n",
    "        policy_entropy = [agent.policy_entropy for agent in agents]\n",
    "        npi = agents[0].posterior_policies.shape[2]\n",
    "        taus = np.arange(ntrials)\n",
    "        ts = np.arange(t)\n",
    "        cs = np.arange(nc)\n",
    "        pis = np.arange(npi)\n",
    "\n",
    "        mi = pd.MultiIndex.from_product([taus, ts, pis, cs], names=['trial', 't','policy', 'context'])\n",
    "        dfs = [None for _ in range(nw)]\n",
    "        factor = ntrials*nc*t*npi\n",
    "\n",
    "        for w in range(nw):\n",
    "            df =  pd.Series(index=mi, data=agents[w].posterior_policies.flatten())\n",
    "            df = df.reset_index().rename(columns = {0:'policy_post'})\n",
    "\n",
    "            prior_policies = np.tile(agents[w].prior_policies[:,np.newaxis,:,:], (1,t,1,1))\n",
    "            policy_prior_df =  pd.Series(index=mi, data=prior_policies.flatten())\n",
    "            policy_prior_df = policy_prior_df.reset_index().rename(columns = {0:'policy_prior'})\n",
    "\n",
    "            policy_like_df =  pd.Series(index=mi, data=agents[w].likelihood.flatten())\n",
    "            policy_like_df = policy_like_df.reset_index().rename(columns = {0:'policy_likelihood'})\n",
    "            df['policy_prior'] = policy_prior_df['policy_prior']\n",
    "            df['policy_like'] = policy_like_df['policy_likelihood']\n",
    "            post_context = np.tile(posterior_context[w][:,:,np.newaxis,:], (1,1,npi,1))\n",
    "            # print(np.all(post_context[:,:,0,:] == post_context[:,:,3,:]))\n",
    "\n",
    "            post_context_df = pd.Series(index=mi, data=post_context.flatten())\n",
    "            post_context_df = post_context_df.reset_index().rename(columns = {0:'post_context'})\n",
    "            df['post_context'] = post_context_df['post_context']\n",
    "            df['learn_rew'] = np.repeat(meta['learn_rew'], factor)\n",
    "            df['switch_cues'] = np.repeat(meta['switch_cues'], factor)\n",
    "            df['contingency_degradation'] = np.repeat(meta['contingency_degradation'], factor)\n",
    "            df['trials_per_block'] = np.repeat(meta['trials_per_block'], factor)\n",
    "            df['degradation_blocks'] = np.repeat(meta['degradation_blocks'], factor)\n",
    "            df['training_blocks'] = np.repeat(meta['training_blocks'], factor)\n",
    "            df['context_cues'] = np.repeat(worlds[0].environment.context_cues, nc*t*npi)\n",
    "            df['true_optimal'] = np.repeat(meta['optimal_sequence'], nc*t*npi)\n",
    "            df['q'] = np.repeat(meta['context_trans_prob'], factor)\n",
    "            df['p'] = np.repeat(meta['cue_ambiguity'], factor)\n",
    "            df['h'] = np.repeat(meta['h'], factor)\n",
    "            df['run'] = np.repeat(w,factor)\n",
    "            df['trial_type'] = np.repeat(meta['trial_type'], nc*t*npi)\n",
    "            df['trial'] = np.repeat(np.arange(ntrials), nc*t*npi)\n",
    "            df['agent'] = np.repeat(w+f*nw,factor)\n",
    "            dfs[w] = df\n",
    "\n",
    "        overall_df[f] = pd.concat(dfs)\n",
    "    data_animation = pd.concat(overall_df)\n",
    "    # data_animation.to_excel('data_animation.xlsx')\n",
    "    return data_animation\n",
    "\n",
    "\n",
    "def load_df_reward_dkl(names,data_folder='temp',nc=4):\n",
    "\n",
    "    path = os.path.join(os.getcwd(),data_folder)\n",
    "    #     names = os.listdir(path)\n",
    "\n",
    "    for fi, f in enumerate(names):\n",
    "        names[fi] = os.path.join(path,f)\n",
    "\n",
    "    dfs = [None]*len(names)\n",
    "\n",
    "    planet_reward_probs = np.array([[0.95, 0   , 0   ],\n",
    "                            [0.05, 0.95, 0.05],\n",
    "                            [0,    0.05, 0.95]])  \n",
    "\n",
    "    planet_reward_probs_switched = np.array([[0   , 0    , 0.95],\n",
    "                                            [0.05, 0.95 , 0.05],\n",
    "                                            [0.95, 0.05 , 0.0]])\n",
    "    \n",
    "    planet_reward_probs = np.tile(planet_reward_probs[:,:,np.newaxis], (1,1,nc))\n",
    "    planet_reward_probs_switched = np.tile(planet_reward_probs_switched[:,:,np.newaxis], (1,1,nc))\n",
    "\n",
    "    overall_df = [None for _ in range(len(names))]\n",
    "\n",
    "    for f,fname in enumerate(names):\n",
    "        jsonpickle_numpy.register_handlers()\n",
    "        with open(fname, 'r') as infile:\n",
    "            data = json.load(infile)\n",
    "                         \n",
    "        worlds = pickle.decode(data)\n",
    "        meta = worlds[-1]\n",
    "        agents = [w.agent for w in worlds[:-1]]\n",
    "        perception = [w.agent.perception for w in worlds[:-1]]\n",
    "        reward_probs = [agent.posterior_dirichlet_rew for agent in agents]\n",
    "        \n",
    "        nt = worlds[0].T\n",
    "        npl = perception[0].npl\n",
    "        nr = worlds[0].agent.nr\n",
    "        nc = perception[0].nc\n",
    "        nw = len(worlds[:-1])\n",
    "        ntrials = meta['trials']\n",
    "\n",
    "        learn_rew = np.repeat(meta['learn_rew'], ntrials*nw*nt)\n",
    "        switch_cues = np.repeat(meta['switch_cues'], ntrials*nw*nt)\n",
    "        contingency_degradation = np.repeat(meta['contingency_degradation'], ntrials*nw*nt)\n",
    "        ntrials_df = np.repeat(meta['trials_per_block'], ntrials*nw*nt)\n",
    "        ndb = np.repeat(meta['degradation_blocks'], ntrials*nw*nt)\n",
    "        ntb = np.repeat(meta['training_blocks'], ntrials*nw*nt)\n",
    "        post_dir_rewards = [a.posterior_dirichlet_rew for a in agents]\n",
    "        post_dir_rewards = [post[:,1:,:,:] for post in post_dir_rewards]\n",
    "        entropy_rewards = np.zeros([nw*ntrials*nt,nc])\n",
    "        extinguished = np.zeros(ntrials*nw*nt, dtype='int32')\n",
    "        extinguished[:] = int(extinguish == True)\n",
    "        \n",
    "        # define true distribution reward\n",
    "        if f == 0:\n",
    "            tpb = meta['trials_per_block']\n",
    "            db = meta['degradation_blocks']\n",
    "            tb = meta['training_blocks']\n",
    "            p= np.tile(planet_reward_probs[np.newaxis,np.newaxis,:,:,:], (ntrials, nt, 1,1,1))\n",
    "            p[tb*tpb:(tb+db)*tpb,:,:,:,:] = \\\n",
    "                np.tile(planet_reward_probs_switched[np.newaxis,np.newaxis,:,:,:],\n",
    "                       ((db + tb)*tpb - tb*tpb, nt, 1,1,1))\n",
    "            p[p == 0] = 10**(-300)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        factor = ntrials*nt*nc\n",
    "        taus = np.arange(ntrials)\n",
    "        ts = np.arange(nt)\n",
    "        # npls = np.char.add(np.asarray(['pl_' for _ in range(npl)]), np.asarray([str(i) for i in range(npl)]))\n",
    "        npls = np.arange(npl)\n",
    "        nrs = np.arange(nr)\n",
    "        cs = np.arange(nc)\n",
    "        mi = pd.MultiIndex.from_product([taus, ts, npls, cs],\n",
    "                names=['trial', 't', 'planet', 'context'])\n",
    "        # dfs_dkl = [None for _ in range(nw)]\n",
    "        # factor = ntrials*nt*nr*npl*nc\n",
    "\n",
    "        dkl_df = [None for _ in range(nw)]\n",
    "        for w in range(nw):\n",
    "            q = reward_probs[w]\n",
    "            e = (db+tb)*tpb\n",
    "            q[e:,:,:,:,:] = np.tile(q[e-1,:,:,:,:], (2*tpb,1,1,1,1))\n",
    "            q[q == 0] = 10**(-300)\n",
    "            norm = 1/(q.sum(axis=2))\n",
    "            q = np.einsum('etrpc, etpc -> etrpc', q, norm)\n",
    "            dkl = (q*np.log(q/p)).sum(axis=2)\n",
    "            df =  pd.Series(index=mi, data=dkl.flatten())\n",
    "            df = df.unstack(level = 'planet')\n",
    "            df = df.reset_index().rename(columns = {0:'p0_dkl', 1:'p1_dkl', 2:'p2_dkl'})\n",
    "            df['avg_dkl'] = (df['p0_dkl'] + df['p1_dkl'] + df['p2_dkl'])/3\n",
    "            df['learn_rew'] = np.repeat(meta['learn_rew'], factor)\n",
    "            df['switch_cues'] = np.repeat(meta['switch_cues'], factor)\n",
    "            df['contingency_degradation'] = np.repeat(meta['contingency_degradation'], factor)\n",
    "            df['trials_per_block'] = np.repeat(meta['trials_per_block'], factor)\n",
    "            df['degradation_blocks'] = np.repeat(meta['degradation_blocks'], factor)\n",
    "            df['training_blocks'] = np.repeat(meta['training_blocks'], factor)\n",
    "            df['context_cues'] = np.repeat(worlds[0].environment.context_cues, nc*nt)\n",
    "            df['true_optimal'] = np.repeat(meta['optimal_sequence'], nc*nt)\n",
    "            df['q'] = np.repeat(meta['context_trans_prob'], factor)\n",
    "            df['p'] = np.repeat(meta['cue_ambiguity'], factor)\n",
    "            df['h'] = np.repeat(meta['h'], factor)\n",
    "            df['run'] = np.repeat(w,factor)\n",
    "            df['trial_type'] = np.repeat(meta['trial_type'], nc*nt)\n",
    "            df['trial'] = np.repeat(np.arange(ntrials), nc*nt)\n",
    "            df['agent'] = np.repeat(w+f*nw,factor)\n",
    "            dkl_df[w] = df\n",
    "        #     break\n",
    "        # break\n",
    "        overall_df[f] = pd.concat(dkl_df)\n",
    "    data = pd.concat(overall_df)\n",
    "    return data\n",
    "\n",
    "\n",
    "def explore_counts(names,data_folder='temp',nc=4):\n",
    "\n",
    "    path = os.path.join(os.getcwd(),data_folder)\n",
    "    #     names = os.listdir(path)\n",
    "\n",
    "    for fi, f in enumerate(names):\n",
    "        names[fi] = os.path.join(path,f)\n",
    "\n",
    "    dfs = [None]*len(names)\n",
    "\n",
    "    planet_reward_probs = np.array([[0.95, 0   , 0   ],\n",
    "                            [0.05, 0.95, 0.05],\n",
    "                            [0,    0.05, 0.95]])  \n",
    "\n",
    "    planet_reward_probs_switched = np.array([[0   , 0    , 0.95],\n",
    "                                            [0.05, 0.95 , 0.05],\n",
    "                                            [0.95, 0.05 , 0.0]])\n",
    "    \n",
    "    planet_reward_probs = np.tile(planet_reward_probs[:,:,np.newaxis], (1,1,nc))\n",
    "    planet_reward_probs_switched = np.tile(planet_reward_probs_switched[:,:,np.newaxis], (1,1,nc))\n",
    "\n",
    "    overall_df = [None for _ in range(len(names))]\n",
    "\n",
    "    for f,fname in enumerate(names):\n",
    "        jsonpickle_numpy.register_handlers()\n",
    "        with open(fname, 'r') as infile:\n",
    "            data = json.load(infile)\n",
    "                         \n",
    "        worlds = pickle.decode(data)\n",
    "        meta = worlds[-1]\n",
    "        agents = [w.agent for w in worlds[:-1]]\n",
    "        perception = [w.agent.perception for w in worlds[:-1]]\n",
    "        reward_probs = [agent.posterior_dirichlet_rew for agent in agents]\n",
    "        \n",
    "        nt = worlds[0].T\n",
    "        npl = perception[0].npl\n",
    "        nr = worlds[0].agent.nr\n",
    "        nc = perception[0].nc\n",
    "        nw = len(worlds[:-1])\n",
    "        ntrials = meta['trials']\n",
    "\n",
    "        learn_rew = np.repeat(meta['learn_rew'], ntrials*nw*nt)\n",
    "        switch_cues = np.repeat(meta['switch_cues'], ntrials*nw*nt)\n",
    "        contingency_degradation = np.repeat(meta['contingency_degradation'], ntrials*nw*nt)\n",
    "        ntrials_df = np.repeat(meta['trials_per_block'], ntrials*nw*nt)\n",
    "        ndb = np.repeat(meta['degradation_blocks'], ntrials*nw*nt)\n",
    "        ntb = np.repeat(meta['training_blocks'], ntrials*nw*nt)\n",
    "        post_dir_rewards = [a.posterior_dirichlet_rew for a in agents]\n",
    "        post_dir_rewards = [post[:,1:,:,:] for post in post_dir_rewards]\n",
    "        entropy_rewards = np.zeros([nw*ntrials*nt,nc])\n",
    "        extinguished = np.zeros(ntrials*nw*nt, dtype='int32')\n",
    "        extinguished[:] = int(extinguish == True)\n",
    "        \n",
    "        # define true distribution reward\n",
    "        if f == 0:\n",
    "            tpb = meta['trials_per_block']\n",
    "            db = meta['degradation_blocks']\n",
    "            tb = meta['training_blocks']\n",
    "            p= np.tile(planet_reward_probs[np.newaxis,np.newaxis,:,:,:], (ntrials, nt, 1,1,1))\n",
    "            p[tb*tpb:(tb+db)*tpb,:,:,:,:] = \\\n",
    "                np.tile(planet_reward_probs_switched[np.newaxis,np.newaxis,:,:,:],\n",
    "                       ((db + tb)*tpb - tb*tpb, nt, 1,1,1))\n",
    "            p[p == 0] = 10**(-300)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        factor = ntrials*nt*nc\n",
    "        taus = np.arange(ntrials)\n",
    "        ts = np.arange(nt)\n",
    "        # npls = np.char.add(np.asarray(['pl_' for _ in range(npl)]), np.asarray([str(i) for i in range(npl)]))\n",
    "        npls = np.arange(npl)\n",
    "        nrs = np.arange(nr)\n",
    "        cs = np.arange(nc)\n",
    "        mi = pd.MultiIndex.from_product([taus, ts, nrs, npls, cs],\n",
    "                names=['trial', 't', 'rewards','planet', 'context'])\n",
    "\n",
    "        # dfs_dkl = [None for _ in range(nw)]\n",
    "        # factor = ntrials*nt*nr*npl*nc\n",
    "\n",
    "        dkl_df = [None for _ in range(nw)]\n",
    "        for w in range(nw):\n",
    "            q = reward_probs[w]\n",
    "            q[q == 0] = 10**(-300)\n",
    "            df =  pd.Series(index=mi, data=q.flatten())\n",
    "            df = df.unstack(level = 'planet')\n",
    "            df = df.unstack(level = 'rewards')\n",
    "            # norm = 1/(q.sum(axis=2))\n",
    "            # q = np.einsumparam_dict('etrpc, etpc -> etrpc', q, norm)\n",
    "            # dkl = (q*np.log(q/p)).sum(axis=2)\n",
    "            # df = df.reset_index().rename(columns = {0:'p0_dkl', 1:'p1_dkl', 2:'p2_dkl'})\n",
    "            # dkl_df[w] = df\n",
    "            break\n",
    "        break\n",
    "    #     overall_df[f] = pd.concat(dkl_df)\n",
    "    # data = pd.concat(overall_df)\n",
    "\n",
    "    return df\n",
    "# df_dkl = load_df_reward_dkl(names)\n",
    "\n",
    "\n",
    "# df = load_df_animation_pol(names)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Load Data  <a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>sequence</th>\n",
       "      <th>starts</th>\n",
       "      <th>planets</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>block</th>\n",
       "      <th>degradation_blocks</th>\n",
       "      <th>training_blocks</th>\n",
       "      <th>interlace</th>\n",
       "      <th>contingency_degradation</th>\n",
       "      <th>switch_cues</th>\n",
       "      <th>trials_per_block</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 2, 1, 0, 2]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1, 0, 2, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 2, 1, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 2, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 2, 1, 2]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   context  sequence  starts             planets  trial_type  block  \\\n",
       "0        1         6       3  [0, 0, 2, 1, 0, 2]           0    0.0   \n",
       "1        0         3       3  [0, 1, 0, 2, 1, 0]           0    0.0   \n",
       "2        1         6       2  [0, 0, 2, 1, 1, 0]           0    0.0   \n",
       "3        1         6       2  [0, 0, 2, 0, 0, 0]           0    0.0   \n",
       "4        0         3       0  [0, 1, 0, 2, 1, 2]           0    0.0   \n",
       "\n",
       "   degradation_blocks  training_blocks  interlace  contingency_degradation  \\\n",
       "0                   2                2       True                     True   \n",
       "1                   2                2       True                     True   \n",
       "2                   2                2       True                     True   \n",
       "3                   2                2       True                     True   \n",
       "4                   2                2       True                     True   \n",
       "\n",
       "   switch_cues  trials_per_block  \n",
       "0        False                70  \n",
       "1        False                70  \n",
       "2        False                70  \n",
       "3        False                70  \n",
       "4        False                70  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(os.path.join(os.getcwd(),'config/ordered/config_degradation_1_switch_0_train2_degr2_n70.json'))\n",
    "data = json.load(f)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files to load: 1\n",
      "['hier_switch0_degr1_p0.9_learn_rew0_q0.9_h100_70_22_dec1_ordered_extinguish.json']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_type</th>\n",
       "      <th>run</th>\n",
       "      <th>trial</th>\n",
       "      <th>t</th>\n",
       "      <th>true_optimal</th>\n",
       "      <th>cue</th>\n",
       "      <th>q</th>\n",
       "      <th>p</th>\n",
       "      <th>h</th>\n",
       "      <th>inferred_context_t0</th>\n",
       "      <th>...</th>\n",
       "      <th>entropy_context</th>\n",
       "      <th>switch_cues</th>\n",
       "      <th>contingency_degradation</th>\n",
       "      <th>degradation_blocks</th>\n",
       "      <th>training_blocks</th>\n",
       "      <th>trials_per_block</th>\n",
       "      <th>dec_temp</th>\n",
       "      <th>ith_cue_trial</th>\n",
       "      <th>policy_optimality_cue</th>\n",
       "      <th>context_optimal_cue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393661</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393661</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393661</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392822</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328883</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trial_type  run  trial  t  true_optimal  cue    q    p    h  \\\n",
       "0           0    0      0  0             6    1  0.9  0.9  100   \n",
       "1           0    0      0  1             6    1  0.9  0.9  100   \n",
       "2           0    0      0  2             6    1  0.9  0.9  100   \n",
       "3           0    0      0  3             6    1  0.9  0.9  100   \n",
       "4           0    0      1  0             3    0  0.9  0.9  100   \n",
       "\n",
       "   inferred_context_t0  ...  entropy_context  switch_cues  \\\n",
       "0                    1  ...         0.393661        False   \n",
       "1                    1  ...         0.393661        False   \n",
       "2                    1  ...         0.393661        False   \n",
       "3                    1  ...         0.392822        False   \n",
       "4                    0  ...         0.328883        False   \n",
       "\n",
       "   contingency_degradation  degradation_blocks  training_blocks  \\\n",
       "0                     True                   2                2   \n",
       "1                     True                   2                2   \n",
       "2                     True                   2                2   \n",
       "3                     True                   2                2   \n",
       "4                     True                   2                2   \n",
       "\n",
       "   trials_per_block  dec_temp  ith_cue_trial  policy_optimality_cue  \\\n",
       "0                70         1              1                    1.0   \n",
       "1                70         1              1                    1.0   \n",
       "2                70         1              1                    1.0   \n",
       "3                70         1              1                    1.0   \n",
       "4                70         1              1                    1.0   \n",
       "\n",
       "   context_optimal_cue  \n",
       "0                  1.0  \n",
       "1                  1.0  \n",
       "2                  1.0  \n",
       "3                  1.0  \n",
       "4                  1.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h =  [1, 2,3,4,5,6,7]#,8,9,10,11,12,13,14,15,16,17,18,19,20,30,40,50,60,70,80,90,100,200]\n",
    "h = [100]\n",
    "cue_ambiguity = [0.9]#, 0.8]                       \n",
    "context_trans_prob = [0.9]#, 0.92, 0.93, 0.95, 0.97, 0.99]                \n",
    "degradation = [True]\n",
    "cue_switch = [False]\n",
    "reward_naive = [False]\n",
    "training_blocks = [2]\n",
    "degradation_blocks=[2]\n",
    "trials_per_block=[70]\n",
    "dec_temp = [1]#,2,3,4,5,6]\n",
    "conf = ['ordered']\n",
    "\n",
    "arrays = [cue_switch, degradation, reward_naive, context_trans_prob, cue_ambiguity,h,\\\n",
    "        training_blocks, degradation_blocks, trials_per_block,dec_temp,conf]\n",
    "\n",
    "extinguish = True\n",
    "names = load_file_names(arrays)\n",
    "print(names)\n",
    "# df = load_df(names, data_folder='temp/old',extinguish=extinguish)\n",
    "df = load_df(names, data_folder='temp',extinguish=extinguish)\n",
    "# df_dkl = load_df_reward_dkl(names, data_folder='temp')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy and context optimality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# context plot\n",
    "\n",
    "# base query parameters\n",
    "switch = False\n",
    "contingency_degr = True\n",
    "reward_naive = False\n",
    "q = 0.9\n",
    "h = 100\n",
    "t = 3\n",
    "trials_per_block = 70\n",
    "training_blocks = 2\n",
    "degradation_blocks = 2\n",
    "queries = ['p==0.9']\n",
    "cue = 0\n",
    "dec_temp = 1\n",
    "strs = np.array(['switch_cues==', '& contingency_degradation==', '& learn_rew==', '& q==', '& h<=',\\\n",
    "                 '& training_blocks==', '& degradation_blocks==', '& trials_per_block==', '& dec_temp =='],dtype='str')\n",
    "vals = np.array([switch, contingency_degr, reward_naive, q, h,\\\n",
    "                 training_blocks, degradation_blocks, trials_per_block, dec_temp], dtype='str')\n",
    "whole_query = np.char.join('', np.char.add(strs, vals))\n",
    "base_query = ' '.join(whole_query.tolist())\n",
    "base_df = df.query(base_query)\n",
    "# base_df_dkl = df_dkl.query(base_query)\n",
    "# queries = ['p==0.95','p==0.7']\n",
    "p = queries[0]\n",
    "context_plot_cue_dependent(p)\n",
    "\n",
    "\n",
    "# dec_temp = 1\n",
    "# strs = np.array(['switch_cues==', '& contingency_degradation==', '& learn_rew==', '& q==', '& h<=',\\\n",
    "#                  '& training_blocks==', '& degradation_blocks==', '& trials_per_block==', '& dec_temp =='],dtype='str')\n",
    "# vals = np.array([switch, contingency_degr, reward_naive, q, h,\\\n",
    "#                  training_blocks, degradation_blocks, trials_per_block, dec_temp], dtype='str')\n",
    "# whole_query = np.char.join('', np.char.add(strs, vals))\n",
    "# base_query = ' '.join(whole_query.tolist())\n",
    "# base_df = df.query(base_query)\n",
    "# # base_df_dkl = df_dkl.query(base_query)\n",
    "# p = queries[0]\n",
    "# context_plot_cue_dependent(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward distribution DKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, axes = plt.subplots(ncols=4, nrows=1, figsize=(20,3))\n",
    "plot_df = base_df_dkl.query('t==3' + ' & p ==' + str(p))\n",
    "cue\n",
    "    \n",
    "for cont in range(4):\n",
    "\n",
    "    # print('context_cues == ' + str(cue) + ' & context== ' + str(cont))\n",
    "    if cont == 3:\n",
    "        sns.lineplot(ax=axes[cont], data=plot_df.query('context== ' + str(cont)),\n",
    "                    x='trial', y='avg_dkl', hue='h', legend=True, \\\n",
    "                    palette=sns.color_palette('Blues_r',n_colors=np.unique(plot_df['h']).size))\n",
    "        print(np.unique(plot_df['h']))\n",
    "        axes[cont].legend(ncol = np.unique(plot_df['h']).size, bbox_to_anchor=(-3.3, -0.3), loc='upper left',\\\n",
    "            borderaxespad=0,title='h')\n",
    "    else:\n",
    "        \n",
    "        sns.lineplot(ax=axes[cont], data=plot_df.query('context== ' + str(cont)),\n",
    "                    x='trial', y='avg_dkl', hue='h',legend=False,\\\n",
    "                        palette=sns.color_palette('Blues_r',n_colors=np.unique(plot_df['h']).size))\n",
    "    axes[cont].set_title('context: ' + str(cont))\n",
    "\n",
    "ranges = plot_df.groupby('trial_type')['trial'].agg(['min', 'max'])\n",
    "cols = [[1,1,1], [0,0,0],[1,1,1]] \n",
    "for ax in axes.flatten():    \n",
    "    for i, row in ranges.iterrows():\n",
    "        ax.axvspan(xmin=row['min'], xmax=row['max'], facecolor=cols[i], alpha=0.05) \n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "# fig, axes = plt.subplots(ncols=2, nrows=4, sharex=True, figsize=(7,10))\n",
    "# plot_df = base_df_dkl.query('t==3' + ' & p ==' + str(p))\n",
    "\n",
    "# for cont in range(4):\n",
    "#     for cue in [0,1]:\n",
    "\n",
    "#         # print('context_cues == ' + str(cue) + ' & context== ' + str(cont))\n",
    "#         if cont == 3 and cue ==1:\n",
    "#             sns.lineplot(ax=axes[cont,cue], data=plot_df.query('context_cues == ' + str(cue) + ' & context== ' + str(cont)),\n",
    "#                      x='trial', y='avg_dkl', hue='h', legend=True, \\\n",
    "#                      palette=sns.color_palette('Blues_r',n_colors=np.unique(plot_df['h']).size))\n",
    "#             print(np.unique(plot_df['h']))\n",
    "#             axes[cont,cue].legend(ncol = np.unique(plot_df['h']).size, bbox_to_anchor=(-1, -1), loc='upper left',\\\n",
    "#               borderaxespad=0,title='h')\n",
    "#         else:\n",
    "            \n",
    "#             sns.lineplot(ax=axes[cont,cue], data=plot_df.query('context_cues == ' + str(cue) + ' & context== ' + str(cont)),\n",
    "#                      x='trial', y='avg_dkl', hue='h',legend=False,\\\n",
    "#                          palette=sns.color_palette('Blues_r',n_colors=np.unique(plot_df['h']).size))\n",
    "#         axes[cont,cue].set_title('context: ' + str(cont) + ' cue: ' + str(cue))\n",
    "# ranges = plot_df.groupby('trial_type')['trial'].agg(['min', 'max'])\n",
    "# cols = [[1,1,1], [0,0,0],[1,1,1]] \n",
    "# for ax in axes.flatten():    \n",
    "#     for i, row in ranges.iterrows():\n",
    "#         ax.axvspan(xmin=row['min'], xmax=row['max'], facecolor=cols[i], alpha=0.05) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Policy optimality zoomed in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ps = [0.8]\n",
    "# switch = False\n",
    "# contingency_degr = True\n",
    "# q = 0.25-0.1\n",
    "# h = 200\n",
    "# t = 3\n",
    "# trials_per_block = 60\n",
    "# training_blocks = 4\n",
    "# degradation_blocks = 4\n",
    "# strs = np.array(['switch_cues==', '& contingency_degradation==', '& q==', '& h<=',\\\n",
    "#                 '& training_blocks==', '& degradation_blocks==', '& trials_per_block=='],dtype='str')\n",
    "# vals = np.array([switch, contingency_degr, q, h,\\\n",
    "#                 training_blocks, degradation_blocks, trials_per_block], dtype='str')\n",
    "# whole_query = np.char.join('', np.char.add(strs, vals))\n",
    "# base_query = ' '.join(whole_query.tolist())\n",
    "# base_df = df.query(base_query)\n",
    "\n",
    "plot_df = base_df.query('trial_type > 0 & trial_type <= 2 &t==0')\n",
    "plot_df = plot_df.astype({'h': 'category'})\n",
    "print(plot_df.size)\n",
    "grouped = plot_df.groupby(by=['agent', 'run','h','cue'])\n",
    "plot_df['policy_optimality_subset'] = grouped['chose_optimal'].transform('cumsum')\n",
    "plot_df['offset'] = grouped['ith_cue_trial'].transform('min')\n",
    "plot_df['policy_optimality_subset'] = plot_df['policy_optimality_subset'] / (plot_df['ith_cue_trial'] - plot_df['offset']+1)\n",
    "cue_degradation = [1,0]\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, nrows=2, figsize = (15,7), sharey=True)\n",
    "plt.tight_layout()\n",
    "for cue in [0,1]:\n",
    "    for pi,p in enumerate(ps):\n",
    "        if pi == 2 and cue==1:\n",
    "            sns.lineplot(ax = axes[cue,pi], data=plot_df.query('learn_rew == '+ str(int(reward_naive))  + ' & p==' + str(p) + ' & cue==' + str(cue)),\\\n",
    "                        x = 'trial',y='policy_optimality_subset', hue='h', legend=True)\n",
    "            axes[cue,pi].set_title('p: ' + str(p) + ' cue: ' + str(cue))\n",
    "        else:\n",
    "            sns.lineplot(ax = axes[cue,pi], data=plot_df.query('learn_rew == '+ str(int(reward_naive)) + ' & p==' + str(p) + ' & cue==' + str(cue)),\\\n",
    "                        x = 'trial',y='policy_optimality_subset', hue='h', legend=False)\n",
    "            axes[cue,pi].set_title('p: ' + str(p) + ' cue: ' + str(cue))\n",
    "\n",
    "    ranges = plot_df.groupby('trial_type')['trial'].agg(['min', 'max'])\n",
    "    cols = [[1,1,1], [0,0,0],[1,1,1]] \n",
    "    for ax in axes.flatten():\n",
    "        for i, row in ranges.iterrows():\n",
    "            ax.axvspan(xmin=row['min'], xmax=row['max'], facecolor=cols[i], alpha=0.05)\n",
    " \n",
    "    ax.legend(bbox_to_anchor=(-2,-0.3), loc='upper left', borderaxespad=0,title='h',ncol=np.unique(plot_df['h'].size))\n",
    "    # fig.suptitle(ttls[f] + ' and cue_degradation: ' + str(cue_degradation[ci]) , fontsize=15, y=1.08)   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 4\n",
    "extinguish = True\n",
    "h =  [1,40]\n",
    "cue_ambiguity = [0.95]                       \n",
    "context_trans_prob = [0.99]                \n",
    "degradation = [True]\n",
    "cue_switch = [False]\n",
    "rew_naive = [False]\n",
    "train_blocks = [2]\n",
    "degr_blocks=[2]\n",
    "tpb=[70]\n",
    "dec_temp = [1]\n",
    "arrays = [cue_switch, degradation, rew_naive, context_trans_prob, cue_ambiguity,h,\\\n",
    "        train_blocks, degr_blocks, tpb, dec_temp]\n",
    "\n",
    "names = load_file_names(arrays, use_fitting=False)\n",
    "# df_context = load_df_animation_context(names, data_folder='temp/old')\n",
    "# df_policy = load_df_animation_pol(names, data_folder='temp/old')\n",
    "df_context = load_df_animation_context(names, data_folder='temp/fitt_hier')\n",
    "# df_policy = load_df_animation_pol(names, data_folder='temp/fitt_hier')\n",
    "# print(np.unique(df_policy['h']).size)\n",
    "\n",
    "# check if values make sense\n",
    "# df[['trial','t','policy', 'context','post_context', 'true_optimal','policy_prior', 'policy_like','policy_post']].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Policy Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animation_figure():\n",
    "    ##### figure 1\n",
    "    fig1 = px.line(plot_df, x='policy', y='policy_prior',animation_frame='trial',animation_group='context',\\\n",
    "        color=\"context\",line_dash = 'h', range_y=[0,1])\n",
    "    fig2 = px.line(plot_df, x='policy', y='policy_like',animation_frame='trial',animation_group='context',\\\n",
    "        color=\"context\",line_dash = 'h', range_y=[0,1])\n",
    "    fig3 = px.line(plot_df, x='policy', y='policy_post',animation_frame='trial',animation_group='context',\\\n",
    "        color=\"context\",line_dash = 'h', range_y=[0,1])\n",
    "    fig4 = px.line(base_df.query(trial_que + ' & t==0' + ' & policy==0'),\\\n",
    "        x='context', y='post_context',animation_frame='trial',animation_group='h', color=\"h\", range_y=[0,1])\n",
    "\n",
    "    # ##### combine\n",
    "\n",
    "    # integrate the two figures, putting second figure on separate axis\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[t for t in fig1.data] \n",
    "            + [t.update(xaxis=\"x2\", yaxis=\"y2\") for t in fig2.data] \n",
    "            + [t.update(xaxis=\"x3\", yaxis=\"y3\") for t in fig3.data] \n",
    "            + [t.update(xaxis=\"x4\", yaxis=\"y4\") for t in fig4.data],\n",
    "        frames=[\n",
    "            go.Frame(\n",
    "                name=fr1.name,\n",
    "                data=[t for t in fr1.data]\n",
    "                + [t.update(xaxis=\"x2\", yaxis=\"y2\") for t in fr2.data]\n",
    "                + [t.update(xaxis=\"x3\", yaxis=\"y3\") for t in fr3.data]\n",
    "                + [t.update(xaxis=\"x4\", yaxis=\"y4\") for t in fr4.data],\n",
    "            )\n",
    "            for fr4, fr3, fr2, fr1 in zip(fig4.frames, fig3.frames, fig2.frames, fig1.frames)\n",
    "        ],\n",
    "        layout=fig1.layout,\n",
    "    )\n",
    "\n",
    "\n",
    "    # now config axes appropriately\n",
    "    fig.update_layout(\n",
    "        xaxis_domain=[0, 0.3],\n",
    "        yaxis_domain=[0, 0.45],\n",
    "        yaxis_range=[0, 1],\n",
    "\n",
    "        xaxis2={\"domain\":[0.33, 0.63], \"matches\": None, \"title\":{\"text\":fig2.layout.xaxis.title.text}},\n",
    "        yaxis2={\"range\": [0,1], \"domain\":[0, 0.45],'position':0.33, \"matches\":None,\"title\":{\"text\":fig2.layout.yaxis.title.text}},\n",
    "\n",
    "        xaxis3={\"domain\": [0.66, 1], \"matches\": None, \"title\":{\"text\":fig3.layout.xaxis.title.text}},\n",
    "        yaxis3={\"range\": [0,1],\"domain\":[0, 0.45], \"matches\": None,'position':0.66, \"title\":{\"text\":fig3.layout.yaxis.title.text}},\n",
    "        xaxis4={\"domain\": [0, 0.5], \"matches\": None,\"showticklabels\":False},\n",
    "        yaxis4={\"range\": [0,1], \"domain\":[0.5, 1], \"matches\": None, \"title\":{\"text\":fig4.layout.yaxis.title.text}},\n",
    "\n",
    "        showlegend=True,\n",
    "    )\n",
    "\n",
    "    for i, frame in enumerate(fig.frames):\n",
    "        frame.layout.title = \"Cue: {}, Trial type: {}\".format(cue, trial_type[i])\n",
    "    for step in fig.layout.sliders[0].steps:\n",
    "        step[\"args\"][1][\"frame\"][\"redraw\"] = True\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "switch = cue_switch[0]\n",
    "contingency_degr = degradation[0]\n",
    "reward_naive = rew_naive[0]\n",
    "q = context_trans_prob[0]\n",
    "h = 1\n",
    "cue = 0\n",
    "trials_per_block = tpb[0]\n",
    "training_blocks = train_blocks[0]\n",
    "degradation_blocks = degr_blocks[0]\n",
    "p = cue_ambiguity[0]\n",
    "strs = np.array(['switch_cues == ', '& contingency_degradation==', '& learn_rew==', '& q==', '& h>=',\\\n",
    "                 '& training_blocks == ', '& degradation_blocks == ', '& trials_per_block ==', '& p =='],dtype='str')\n",
    "vals = np.array([switch, contingency_degr, reward_naive, q, h,\\\n",
    "                 training_blocks, degradation_blocks, trials_per_block, p], dtype='str')\n",
    "whole_query = np.char.join('', np.char.add(strs, vals))\n",
    "base_query = ' '.join(whole_query.tolist())\n",
    "base_df = df_policy.query(base_query)\n",
    "# trial_que = 'trial > 200 & trial <300 & context_cues ==' + str(cue)\n",
    "trial_que = 'trial_type >=0  & context_cues ==' + str(cue)\n",
    "plot_df = base_df.query(trial_que + ' & t==0' + ' & (context == 0 | context == 2)')\n",
    "trial_type = plot_df.groupby(by=['trial'])['trial_type'].mean().to_numpy().astype('int32')\n",
    "print(np.unique(plot_df['h']).size)\n",
    "animation_figure()\n",
    "base_query\n",
    "# cue = 1\n",
    "# trial_que = 'trial_type >0  & context_cues ==' + str(cue)\n",
    "# plot_df = base_df.query(trial_que + ' & t==0')\n",
    "# trial_type = plot_df.groupby(by=['trial'])['trial_type'].mean().to_numpy().astype('int32')\n",
    "\n",
    "# animation_figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = plot_df.query('policy==0').set_index(['agent','trial','t','context'])['post_context']\n",
    "test = test.unstack(level='context').query('trial > 220')\n",
    "# test.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For h1 the habits are built up for the 4 contexts, the habit strength is comparanble for the different pairs of contexts (c0 and c2; c1 and c3) since p=0.6 and even though agent discerns the correct context it is by very little. During degradation the habit is erroded for the degradation contexts (context 2 and context 3) because of the switched reward contingencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch = cue_switch[0]\n",
    "contingency_degr = degradation[0]\n",
    "reward_naive = rew_naive[0]\n",
    "q = context_trans_prob[0]\n",
    "h = 1\n",
    "cue = 0\n",
    "trials_per_block = tpb[0]\n",
    "training_blocks = train_blocks[0]\n",
    "degradation_blocks = degr_blocks[0]\n",
    "p = cue_ambiguity[0]\n",
    "dt = dec_temp[0]\n",
    "\n",
    "strs = np.array(['switch_cues == ', '& contingency_degradation==', '& learn_rew==', '& q==', '& h>=',\\\n",
    "                 '& training_blocks == ', '& degradation_blocks == ', '& trials_per_block =='],dtype='str')\n",
    "vals = np.array([switch, contingency_degr, reward_naive, q, h,\\\n",
    "                 training_blocks, degradation_blocks, trials_per_block], dtype='str')\n",
    "whole_query = np.char.join('', np.char.add(strs, vals))\n",
    "base_query = ' '.join(whole_query.tolist())\n",
    "base_df = df_context.query(base_query + ' & context_cues ==' + str(cue))\n",
    "\n",
    "plot_df = base_df.query('t==3'+ ' & (h==1 | h==100)')\n",
    "\n",
    "\n",
    "trial_type = plot_df.groupby(by=['trial'])['trial_type'].mean().to_numpy().astype('int32')\n",
    "plot_df = plot_df.query('trial_type==1')\n",
    "##### figure 1\n",
    "fig1 = px.line(plot_df, x='context', y='probability',animation_frame='trial',animation_group='h', color=\"h\", range_y=[0,1])\n",
    "# fig1.show()\n",
    "fig2 = px.line(plot_df, x='context', y='outcome_surprise',animation_frame='trial',animation_group='h', color=\"h\", range_y=\\\n",
    "               [np.min(plot_df.outcome_surprise), np.max(plot_df.outcome_surprise)])\n",
    "\n",
    "# fig2.show()\n",
    "# print([np.min(plot_df.outcome_surprise), np.max(plot_df.outcome_surprise)])\n",
    "# print([np.min(base_df.policy_entropy), np.max(base_df.policy_entropy)])\n",
    "fig3 = px.line(base_df.query('context_cues ==' + str(cue) + ' & t==1  & (h==1 | h==100)'), x='context',\\\n",
    "               y='policy_entropy',animation_frame='trial',animation_group='h', color=\"h\", range_y = \\\n",
    "    [np.min(base_df.policy_entropy), np.max(base_df.policy_entropy)])\n",
    "# fig3.show()\n",
    "\n",
    "trial_type = plot_df.groupby(by=['trial'])['trial_type'].mean().to_numpy().astype('int32')\n",
    "\n",
    "# ##### combine\n",
    "\n",
    "\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[t for t in fig1.data] \n",
    "         + [t.update(xaxis=\"x2\", yaxis=\"y2\") for t in fig2.data] \n",
    "         + [t.update(xaxis=\"x3\", yaxis=\"y3\") for t in fig3.data],\n",
    "    frames=[\n",
    "        go.Frame(\n",
    "            name=fr1.name,\n",
    "            data=[t for t in fr1.data]\n",
    "            + [t.update(xaxis=\"x2\", yaxis=\"y2\") for t in fr2.data]\n",
    "            + [t.update(xaxis=\"x3\", yaxis=\"y3\") for t in fr3.data],\n",
    "        )\n",
    "        for fr3, fr2, fr1 in zip(fig3.frames, fig2.frames, fig1.frames)\n",
    "    ],\n",
    "    layout=fig1.layout,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# now config axes appropriately\n",
    "fig.update_layout(\n",
    "    xaxis_domain=[0, 0.45],\n",
    "    yaxis_domain=[0, 0.45],\n",
    "\n",
    "    xaxis2={\"domain\":[0.5, 1], \"matches\": None, \"title\":{\"text\":fig2.layout.xaxis.title.text}},\n",
    "    yaxis2={\"domain\":[0, 0.45], \"matches\":None, \"range\": [-20,0], \"position\":0.49, \"title\":{\"text\":fig2.layout.yaxis.title.text}},\n",
    "\n",
    "    xaxis3={\"domain\": [0, 0.45], \"matches\": None, \"title\":{\"text\":fig3.layout.xaxis.title.text}},\n",
    "    yaxis3={\"domain\":[0.5, 1], \"matches\": None, \"range\": [0,2], \"title\":{\"text\":fig3.layout.yaxis.title.text}},\n",
    "\n",
    "#     # xaxis4={\"domain\": [0.34, 0.66], \"matches\": None, \"title\":{\"text\":fig4.layout.xaxis.title.text}},\n",
    "#     # yaxis4={\"domain\":[0.5, 1], \"matches\": None,'position':0.33, \"title\":{\"text\":fig4.layout.yaxis.title.text}},\n",
    "\n",
    "#     # xaxis5={\"domain\": [0.67, 1], \"matches\": None, \"title\":{\"text\":fig5.layout.xaxis.title.text}},\n",
    "#     # yaxis5={\"domain\":[0.5, 1], \"matches\": None,'position':0.66, \"title\":{\"text\":fig5.layout.yaxis.title.text}},\n",
    "#     showlegend=True\n",
    ")\n",
    "\n",
    "for i, frame in enumerate(fig.frames):\n",
    "    frame.layout.title = \"Cue: {}, Trial type: {}\".format(cue, trial_type[i])\n",
    "for step in fig.layout.sliders[0].steps:\n",
    "    step[\"args\"][1][\"frame\"][\"redraw\"] = True\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_query"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cff3abf1678755e0069fd79299a535fe1940bcd71a6b01d9f4386710b2b163f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "289px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
